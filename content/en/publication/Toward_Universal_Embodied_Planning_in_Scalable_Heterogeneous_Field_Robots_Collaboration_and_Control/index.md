---
title: "Toward Universal Embodied Planning in Scalable Heterogeneous Field Robots Collaboration and Control"
authors:
- wanhanwen
- Zhang Yuhan
- Wang Junjie
- Wu Donghao
- Li Mengkang
- chenxilun
- Deng Yixuan
- Huang Yuxuan
- Sun Zhenglong
- Zhang Lin
- jixiaoqiang
author_notes:
- "Equal contribution"
- "Equal contribution"
- ""
- ""
- ""
- ""
- ""
- ""
- ""
- ""
- "Corresponding author"
date: "2025-01-05T00:00:00Z"
doi: "https://doi.org/10.1002/rob.22522"

# Schedule page publish date (NOT publication's date).
# publishDate: "2025-03-11T00:00:00Z"

# Publication type.
# Accepts a single type but formatted as a YAML list (for Hugo requirements).
# Enter a publication type from the CSL standard.
publication_types: ["article-journal"]

# Publication name and optional abbreviated publication name.
publication: "*Journal of Field Robotics, 42*(5)"
publication_short: "JFR"

abstract: Multi‐robot systems offer substantial enhancements in efficiency, scalability, robustness, and flexibility for executing complex tasks through collaborative efforts. However, existing methodologies are constrained by their lack of generalizability, the need for extensive modeling, and most importantly, limitations in their applicability in complex scenarios. This paper presents a novel approach to multi‐robot task planning and coordination, introducing a comprehensive pipeline encompassing data generation, supervised fine‐tuning, and rigorous error analysis using the Multi‐Robot collaboration Error Diagnostic (MRED) metrics. Bridging the gap between natural language commands and physical groundings in robot collaboration tasks, we present MultiPlan &#58; the first data set specifically designed for LLM fine‐tuning. The MultiPlan data set encompasses 100 distinct indoor and outdoor scenarios, ranging from office to garden. Experiments underscore the efficacy of the proposed methodology, including comparative analyses against state‐of‐the‐art LLMs and generalization studies on previously unseen tasks. Results reveal that the fine‐tuned model achieves a 24.8% relative improvement over the GPT‐4 model in addressing complex multi‐robot planning scenarios. We also conducted field evaluations in both office and urban settings to demonstrate the deployment performance of the proposed method. These results demonstrate the model's superior capabilities in task decomposition, error management, and adaptation to novel contexts.

# Summary. An optional shortened abstract.
summary: embodied artificial intelligence | large language model | multi‐robot task planning | supervised fine‐tune

tags:
- Embodied Robotics
featured: false # 是否为特色/重点出版物

links:
- name: "Pdf Download"
  url: files/publication/Journal_of_Field_Robotics-2025-Wan-Toward_Universal_Embodied_Planning_in_Scalable_Heterogeneous_Field_Robots.pdf
url_pdf: https://onlinelibrary.wiley.com/doi/10.1002/rob.22522
url_code: ''
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: ''
url_video: ''

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
# image:
#   caption: 'Image credit: [**Unsplash**](https://unsplash.com/photos/jdD8gXaTZsc)'
#   focal_point: ""
#   preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects: []

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: ""
---

<!-- {{% callout note %}}
Click the *Cite* button above to demo the feature to enable visitors to import publication metadata into their reference management software.
{{% /callout %}}

{{% callout note %}}
Create your slides in Markdown - click the *Slides* button to check out the example.
{{% /callout %}} -->

<!-- Add the publication's **full text** or **supplementary notes** here. You can use rich formatting such as including [code, math, and images](https://docs.hugoblox.com/content/writing-markdown-latex/). -->
